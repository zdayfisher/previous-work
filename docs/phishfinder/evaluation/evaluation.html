<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>phishfinder.evaluation.evaluation API documentation</title>
<meta name="description" content="Main evaluation module â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>phishfinder.evaluation.evaluation</code></h1>
</header>
<section id="section-intro">
<p>Main evaluation module.</p>
<p>This module provides the evaluate function which acts as a pipeline for
the evaluation module.</p>
<h2 id="purpose">Purpose</h2>
<p>Process domain
data provided by discovery module.
Train the Logistic Regression or Multi-Layer Perceptron Classifier
using the processed data and evaluate model's performance based on its
accuracy, precision and recall.
Use the trained model to decide whether unclassified domains are benign
or phishing.</p>
<h2 id="non-public-functions">Non-Public Functions</h2>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Non-public functions are not part of this API documentation.</p>
<p>For more information on these functions, click "Expand Source Code"
below to view the docstrings in the source code.</p>
</div>
<ul>
<li><code>_is_ip</code></li>
<li><code>_suspicious_characters</code></li>
<li><code>_use_http</code></li>
<li><code>_redirects</code></li>
<li><code>_process_input_data_domain</code>: Processes csv file containing training data with domain information.</li>
<li><code>_process_unknown_data_domain</code>: Processes csv file containing unclassified data with domain information.</li>
<li><code>_prep_domain_data</code>: Selects a limited feature set for known and unknown data and performs One-Hot Encoding</li>
<li><code>_train_lr</code>: Creates a Logistic Regression model and peerfmorms training using provided training data.</li>
<li><code>_train_mlp</code>: Creates a Multi-Layer Perceptron model and peerfmorms training using provided training data.</li>
<li><code>_recall</code>: Calculates the recall for a specific class, given the ground truth and predicted values.</li>
<li><code>_precision</code>: Calculates the precision for a specific class, given the ground truth and predicted values.</li>
<li><code>_accuracy</code>: Calculates the accuracy for a specific class, given the ground truth and predicted values.</li>
<li><code>_evaluate</code>: Evaluates accuracy, precision and recall of a model using provided testing data.</li>
<li><code>_is_benign</code>: Returns a string representation for benign and malicious classes</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Main evaluation module.

This module provides the evaluate function which acts as a pipeline for
the evaluation module.

Purpose
-------
Process domain  data provided by discovery module.
Train the Logistic Regression or Multi-Layer Perceptron Classifier
using the processed data and evaluate model&#39;s performance based on its
accuracy, precision and recall.
Use the trained model to decide whether unclassified domains are benign
or phishing.

Non-Public Functions
--------------------

.. note:: Non-public functions are not part of this API documentation.
    For more information on these functions, click &#34;Expand Source Code&#34;
    below to view the docstrings in the source code.

- `_is_ip`
- `_suspicious_characters`
- `_use_http`
- `_redirects`
- `_process_input_data_domain`: Processes csv file containing training data with domain information.
- `_process_unknown_data_domain`: Processes csv file containing unclassified data with domain information.
- `_prep_domain_data`: Selects a limited feature set for known and unknown data and performs One-Hot Encoding
- `_train_lr`: Creates a Logistic Regression model and peerfmorms training using provided training data.
- `_train_mlp`: Creates a Multi-Layer Perceptron model and peerfmorms training using provided training data.
- `_recall`: Calculates the recall for a specific class, given the ground truth and predicted values.
- `_precision`: Calculates the precision for a specific class, given the ground truth and predicted values.
- `_accuracy`: Calculates the accuracy for a specific class, given the ground truth and predicted values.
- `_evaluate`: Evaluates accuracy, precision and recall of a model using provided testing data.
- `_is_benign`: Returns a string representation for benign and malicious classes
&#34;&#34;&#34;

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn import preprocessing
from sklearn.preprocessing import OneHotEncoder
import datetime
import pandas as pd
import numpy as np
import tldextract
from tqdm import tqdm

from os.path import dirname, join as pjoin



def _is_ip(url):
    &#39;&#39;&#39;
    Check if URL contains an IP address inside
    &#39;&#39;&#39;
    s =  url.find(&#39;//&#39;)
    if s != -1 and len(url) &gt;= s + 14:
        url = url[s+2:s+14]
    return 1 if url.replace(&#39;.&#39;, &#39;&#39;).isnumeric() else 0

def _suspicious_characters(url):
    &#39;&#39;&#39;
    Check if domain name contains suspicious characters such as &#39;@&#39;
    &#39;&#39;&#39;
    return 1 if &#39;@&#39; in url else 0

def _use_http(url):
    &#39;&#39;&#39;
    Check if http:// is used instead of https://
    &#39;&#39;&#39;
    return 1 if &#39;http://&#39; in url else 0

def _redirects(url):
    &#39;&#39;&#39;
    Check if URL redirects you to another final URL
    &#39;&#39;&#39;
    return False

def _process_input_data_domain(max_rows):
    &#39;&#39;&#39;
    Returns the dataframe containing information about benign and malicious domains
    &#39;&#39;&#39;
    df = pd.read_csv(pjoin(dirname(__file__), &#34;data/training_data/benign_certs.csv&#34;))
    df[&#39;phishing&#39;] = df.apply(lambda row: 0, axis = 1)

    df_malicious = pd.read_csv(pjoin(dirname(__file__), &#34;data/training_data/malicious_certs.csv&#34;))
    df_malicious[&#39;phishing&#39;] = df_malicious.apply(lambda row: 1, axis = 1)

    df = df.append(df_malicious, ignore_index = True)

    df.dropna(inplace=True)
    
    df[&#39;suspicious-chars&#39;] = df.apply(lambda row: _suspicious_characters(row[&#39;domain-name&#39;]), axis = 1)
    df[&#39;domain-length&#39;] = df.apply(lambda row: len(row[&#39;domain-name&#39;]), axis = 1)

    #shuffle the dataframe
    df = df.sample(frac=1).reset_index(drop=True)
    df = df.iloc[:max_rows, :]

    return df

def _process_unknown_data_domain(df):
    &#39;&#39;&#39;
    Returns the dataframe retrieved by discovery module that needs to be classified.
    &#39;&#39;&#39;
    
    df[&#39;suspicious-chars&#39;] = df.apply(lambda row: _suspicious_characters(row[&#39;domain-name&#39;]), axis = 1)
    df[&#39;domain-length&#39;] = df.apply(lambda row: len(row[&#39;domain-name&#39;]), axis = 1)

    #shuffle the dataframe
    #df = df.sample(frac=1).reset_index(drop=True)
    df = df.iloc[:100, :]

    return df


def _prep_domain_data(discovery_results, max_rows):
    &#39;&#39;&#39;
    Return the One-Hot Encoded version of the train and test split dataframes for the following featureset of the domain certificate data:
        - &#39;suspicious-chars&#39;
        - &#39;domain-length&#39;
        - &#39;issuer-name&#39;
        - &#39;issuer-country&#39;
        - &#39;cert-duration&#39;
        - &#39;issuer-country-count&#39;
    &#39;&#39;&#39;
    feature_set = {&#39;suspicious-chars&#39;, &#39;domain-length&#39;, &#39;issuer-name&#39;, &#39;issuer-country&#39;, &#39;cert-duration&#39;, &#39;issuer-country-count&#39;}
    X = _process_input_data_domain(max_rows)
    X_unknown = _process_unknown_data_domain(discovery_results)

    ohe = OneHotEncoder(sparse=False, handle_unknown=&#39;ignore&#39;)
   
    y = X.pop(&#39;phishing&#39;).values

    X1 = X.groupby(&#39;domain-name&#39;)[&#39;issuer-country&#39;].nunique()  
    X = X.join(X1, on=&#39;domain-name&#39;, rsuffix=&#39;-count&#39;)


    X2 = X_unknown.groupby(&#39;domain-name&#39;)[&#39;issuer-country&#39;].nunique()
    X_unknown = X_unknown.join(X2, on=&#39;domain-name&#39;, rsuffix=&#39;-count&#39;)
    
    X = X[feature_set].copy()
    X_unknown = X_unknown[feature_set].copy()

    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=2)
    ohe.fit(X_train)
    X_train_encoded = ohe.transform(X_train)
    X_val_encoded = ohe.transform(X_val)
    X_unknown_encoded = ohe.transform(X_unknown)

    return X_train_encoded, y_train, X_val_encoded, y_val, X_unknown_encoded

def _recall(actual_tags, predictions, class_of_interest):
    &#39;&#39;&#39;
    Calculates the recall for a specific class, given the ground truth and predicted values.
    &#39;&#39;&#39;
    total_found = 0
    for i in range(len(actual_tags)):
        if (actual_tags[i] == class_of_interest and actual_tags[i] == predictions[i]):
            total_found += 1
    return total_found / np.count_nonzero(actual_tags == class_of_interest)

def _precision(actual_tags, predictions, class_of_interest):
    &#39;&#39;&#39;
    Calculates the precision for a specific class, given the ground truth and predicted values.
    &#39;&#39;&#39;
    total_found = 0
    for i in range(len(actual_tags)):
        if (actual_tags[i] == class_of_interest and actual_tags[i] == predictions[i]):
            total_found += 1
    return total_found / np.count_nonzero(predictions == class_of_interest)

def _accuracy(actual_tags, predictions):
    &#39;&#39;&#39;
    Calculates the average number of correct predictions.
        - actual_tags: The ground truth
        - predictions: What the model predicts
    &#39;&#39;&#39;
    total_found = 0
    for i in range(len(actual_tags)):
        if (actual_tags[i] == predictions[i]):
            total_found += 1
    return total_found / len(predictions)

def _train_lr(X_train, y_train):
    &#39;&#39;&#39;
    Returns a Logistic Regression classifier trained based on provided data.
    &#39;&#39;&#39;
    clf_lr = LogisticRegression(solver=&#39;lbfgs&#39;, max_iter=1000, random_state=1).fit(X_train, y_train)
    return clf_lr

def _train_mlp(X_train, y_train):
    &#39;&#39;&#39;
    Returns a Multi-Layer Perceptron classifier trained based on provided data
    &#39;&#39;&#39;
    clf_mlp = MLPClassifier(solver=&#39;lbfgs&#39;, alpha=1e-4, hidden_layer_sizes=(200, 200), random_state=5, max_iter=120, early_stopping=True, learning_rate_init=0.01, verbose=True, warm_start=True)
    clf_mlp.fit(X_train, y_train)

    return clf_mlp

def _evaluate(model, X_val, y_val):
    &#39;&#39;&#39;
    Returns model&#39;s accuracy, precision, and recall for class 1 (Malicious) data.
    &#39;&#39;&#39;
    predictions = model.predict(X_val)
    return _accuracy(y_val, predictions), _precision(y_val, predictions, 1), _recall(y_val, predictions, 1)

def _is_benign(row):
    &#39;&#39;&#39;
    Returns string representation for 1 (Malicious) and 0 (Benign) classes
    &#39;&#39;&#39;
    if row == 1:
        return &#39;malicious&#39;
    else:
        return &#39;benign&#39;

def evaluation(discovery_results, max_rows = 100000):
    &#34;&#34;&#34;
    Trains a machine learning model based on known benign and malicious
    domains. Evaluates the performance of the model. Uses the model to classify 
    previsouly unknown domains.

    Parameters
    ----------
    discovery_results: pandas.DataFrame
        Pandas DataFrame with information found about each generated
        possible phishing domain.

    max_rows: int
        Maximum number of rows to be used for training the model.

    Returns
    -------
    Returns: pandas.DataFrame
        Returns a pandas DataFrame with information found about each generated
        possible phishing domain and their classfication as benign or malicious.
    &#34;&#34;&#34;
    if discovery_results.empty:
        discovery_results = pd.read_csv(pjoin(dirname(__file__), &#34;data/test_data/netflix_test.csv&#34;))
    
    for i in tqdm(range(1)):
        X_train, y_train, X_val, y_val, X_unknown = _prep_domain_data(discovery_results, max_rows)
    mlp_model = _train_mlp(X_train, y_train)


    train_accuracy, train_prec, train_recall = _evaluate(mlp_model, X_train, y_train)
    test_accuracy, test_prec, test_recall = _evaluate(mlp_model, X_val, y_val)
    
    print(&#34;Accuracy for training data:&#34;, train_accuracy)
    print(&#34;Precision for training data:&#34;, train_prec)
    print(&#34;Recall for training data:&#34;, train_recall)
    print(&#34;Accuracy for test data:&#34;, test_accuracy)
    print(&#34;Precision for test data:&#34;, test_prec)
    print(&#34;Recall for test data:&#34;, test_recall)
    
    predictions = mlp_model.predict(X_unknown)
    
    unknown_df = _process_unknown_data_domain(discovery_results)
    unknown_df[&#39;prediction&#39;] = predictions
    unknown_df[&#39;prediction&#39;] = unknown_df.apply(lambda row: _is_benign(row[&#39;prediction&#39;]), axis = 1)

    print(unknown_df.head(10))


    return unknown_df

#if __name__ == &#39;__main__&#39;:
#    evaluation(pd.DataFrame({&#39;A&#39; : []}))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="phishfinder.evaluation.evaluation.evaluation"><code class="name flex">
<span>def <span class="ident">evaluation</span></span>(<span>discovery_results, max_rows=100000)</span>
</code></dt>
<dd>
<div class="desc"><p>Trains a machine learning model based on known benign and malicious
domains. Evaluates the performance of the model. Uses the model to classify
previsouly unknown domains.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>discovery_results</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>Pandas DataFrame with information found about each generated
possible phishing domain.</dd>
<dt><strong><code>max_rows</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of rows to be used for training the model.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>Returns</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>Returns a pandas DataFrame with information found about each generated
possible phishing domain and their classfication as benign or malicious.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def evaluation(discovery_results, max_rows = 100000):
    &#34;&#34;&#34;
    Trains a machine learning model based on known benign and malicious
    domains. Evaluates the performance of the model. Uses the model to classify 
    previsouly unknown domains.

    Parameters
    ----------
    discovery_results: pandas.DataFrame
        Pandas DataFrame with information found about each generated
        possible phishing domain.

    max_rows: int
        Maximum number of rows to be used for training the model.

    Returns
    -------
    Returns: pandas.DataFrame
        Returns a pandas DataFrame with information found about each generated
        possible phishing domain and their classfication as benign or malicious.
    &#34;&#34;&#34;
    if discovery_results.empty:
        discovery_results = pd.read_csv(pjoin(dirname(__file__), &#34;data/test_data/netflix_test.csv&#34;))
    
    for i in tqdm(range(1)):
        X_train, y_train, X_val, y_val, X_unknown = _prep_domain_data(discovery_results, max_rows)
    mlp_model = _train_mlp(X_train, y_train)


    train_accuracy, train_prec, train_recall = _evaluate(mlp_model, X_train, y_train)
    test_accuracy, test_prec, test_recall = _evaluate(mlp_model, X_val, y_val)
    
    print(&#34;Accuracy for training data:&#34;, train_accuracy)
    print(&#34;Precision for training data:&#34;, train_prec)
    print(&#34;Recall for training data:&#34;, train_recall)
    print(&#34;Accuracy for test data:&#34;, test_accuracy)
    print(&#34;Precision for test data:&#34;, test_prec)
    print(&#34;Recall for test data:&#34;, test_recall)
    
    predictions = mlp_model.predict(X_unknown)
    
    unknown_df = _process_unknown_data_domain(discovery_results)
    unknown_df[&#39;prediction&#39;] = predictions
    unknown_df[&#39;prediction&#39;] = unknown_df.apply(lambda row: _is_benign(row[&#39;prediction&#39;]), axis = 1)

    print(unknown_df.head(10))


    return unknown_df</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#purpose">Purpose</a></li>
<li><a href="#non-public-functions">Non-Public Functions</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="phishfinder.evaluation" href="index.html">phishfinder.evaluation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="phishfinder.evaluation.evaluation.evaluation" href="#phishfinder.evaluation.evaluation.evaluation">evaluation</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>